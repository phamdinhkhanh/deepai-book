
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>8.1. Mô hình cây quyết định (decision tree) &#8212; Deep AI KhanhBlog</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/my.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"TeX": {"Macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://phamdinhkhanh.github.io/deepai-book/ch_ml/DecisionTree.html" />
    <link rel="shortcut icon" href="../_static/logo.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="9. Giới thiệu về mô hình rừng cây (Random Forest)" href="index_RandomForest.html" />
    <link rel="prev" title="8. Khái niệm về cây quyết định" href="index_DecisionTree.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/ML_course_logos.jpeg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Deep AI KhanhBlog</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Lời nói đầu
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../contents.html">
   Các chương dự kiến
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_intro/main_contents.html">
   Mục tiêu cuốn sách
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../latex.html">
   Latex
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../grossary.html">
   Bảng thuật ngữ
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Phụ lục
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/appendix_dtypes.html">
   1. Định dạng dữ liệu
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_dtypes_basic.html">
     1.1. Các định dạng số, boolean và ký tự
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_pandas.html">
   2. Pandas
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pandas.html">
     2.1. Khởi tạo dataframe
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_numpy.html">
   3. Numpy
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_numpy.html">
     3.1. Khởi tạo một mảng trên numpy
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_matplotlib.html">
   4. Matplotlib
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_matplotlib.html">
     4.1. Format chung của một biểu đồ trên matplotlib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_OOP.html">
   5. Lập trình hướng đối tượng (Object Oriented Programming - OOP)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_OOP.html">
     5.1. Class và Object
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_pipeline.html">
   6. Sklearn Pipeline
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_pipeline.html">
     6.1. Thiết kế pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ch_appendix/index_Convex_Opt.html">
   7. Giới thiệu chung về optimization
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ch_appendix/appendix_Convex_Opt.html">
     7.1. Bài toán dạng tổng quát
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Đại số tuyến tính
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_algebra/appendix_algebra.html">
   1. Đại số tuyến tính
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Giới thiệu
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_calculus/appendix_calculus.html">
   1. Giải tích tích phân
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Xác suất
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_probability/appendix_probability.html">
   1. Xác suất
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index_MLIntroduce.html">
   1. Khái quát Machine Learning
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_prediction.html">
   2. Bài toán dự báo
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="prediction.html">
     2.1. Ứng dụng của hồi qui tuyến tính
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_RidgedRegression.html">
   2.2. Hồi qui Ridge và Lasso
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="RidgedRegression.html">
     2.2.2. Hồi qui Ridge
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_classification.html">
   3. Bài toán phân loại
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="classification.html">
     3.1. Hồi qui Logistic
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_OvfAndUdf.html">
   4. Độ chệch (
   <em>
    bias
   </em>
   ) và phương sai (
   <em>
    variance
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="OvfAndUdf.html">
     4.1. Sự đánh đổi giữa độ chệch và phương sai
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_ModelMetric.html">
   5. Thước đo mô hình phân loại
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="modelMetric.html">
     5.1. Bộ dữ liệu
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_creditScorecard.html">
   6. Ứng dụng mô hình scorecard
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="creditScorecard.html">
     6.1. Phương pháp chuyên gia và mô hình
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_SVM.html">
   7. Giới thiệu về SVM
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="SVM.html">
     7.1. Hàm mất mát của SVM
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index_DecisionTree.html">
   8. Khái niệm về cây quyết định
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     8.1. Mô hình cây quyết định (
     <em>
      decision tree
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_RandomForest.html">
   9. Giới thiệu về mô hình rừng cây (
   <em>
    Random Forest
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="RandomForest.html">
     9.1. Ý tưởng của mô hình rừng cây
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_Bayes.html">
   10. Bạn là
   <em>
    Tần suất
   </em>
   (
   <em>
    Frequentist
   </em>
   ) hay
   <em>
    Bayesian
   </em>
   ?
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="NaiveBayes.html">
     10.1. Ước lượng hợp lý tối đa (
     <em>
      Maximum Likelihood Function - MLE
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_FeatureEngineering.html">
   11. Giới thiệu về feature engineering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="FeatureEngineering.html">
     11.1. Feature Engineering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_Boosting.html">
   12. Phương pháp tăng cường (
   <em>
    Boosting
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="Boosting.html">
     12.1. AdaBoosting
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_KMeans.html">
   13. k-Means Clustering
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="KMeans.html">
     13.1. Các bước của thuật toán k-Means Clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_HierarchicalClustering.html">
   14. Hierarchical Clustering (
   <em>
    phân cụm phân cấp
   </em>
   )
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="HierarchicalClustering.html">
     14.1. Chiến lược hợp nhất (
     <em>
      agglomerative
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_DBSCAN.html">
   15. DBSCAN
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="DBSCAN.html">
     15.1. Phương pháp phân cụm dựa trên mật độ (
     <em>
      Density-Based Clustering
     </em>
     )
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_GMM.html">
   16. Gaussian Mixture Model
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="GMM.html">
     16.1. Ước lượng MLE cho
     <em>
      phân phối Gaussian đa chiều
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="index_PCA.html">
   17. Giảm chiều dữ liệu
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
  <label for="toctree-checkbox-24">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="PCA.html">
     17.1. Phương pháp phân tích suy biến
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Đóng góp từ những tác giả khác
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/fubini_and_riemann.html">
   Tích phân Riemann và định lý Fubini
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ch_donation/information_theory.html">
   Lý thuyết thông tin
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/ch_ml/DecisionTree.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ch_ml/DecisionTree.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/phamdinhkhanh/deepai-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/phamdinhkhanh/deepai-book/issues/new?title=Issue%20on%20page%20%2Fch_ml/DecisionTree.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/phamdinhkhanh/deepai-book/edit/main/book/ch_ml/DecisionTree.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/phamdinhkhanh/deepai-book/main?urlpath=tree/book/ch_ml/DecisionTree.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   8.1. Mô hình cây quyết định (
   <em>
    decision tree
   </em>
   )
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bai-toan-phan-loai-cay-quyet-dinh-tren-bo-du-lieu-boston">
   8.2. Bài toán phân loại cây quyết định trên bộ dữ liệu boston
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#duong-bien-phan-chia-cua-cay-quyet-dinh">
   8.3. Đường biên phân chia của cây quyết định
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cach-khoi-tao-cay-quyet-dinh">
   8.4. Cách khởi tạo cây quyết định
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tinh-khiet-va-van-duc">
     8.4.1. Tinh khiết và vẩn đục
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#thuoc-do-cho-muc-do-tinh-khiet-purity">
     8.4.2. Thước đo cho mức độ
     <em>
      tinh khiết
     </em>
     (
     <em>
      purity
     </em>
     )
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tim-kiem-tham-lam-va-truy-hoi">
     8.4.3. Tìm kiếm tham lam và truy hồi
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#thuat-toan-id3-va-cart">
   8.5. Thuật toán ID3 và CART
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#truong-hop-cay-nhi-phan-voi-bien-lien-tuc">
     8.5.1. Trường hợp cây nhị phân với biến liên tục
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#truong-hop-khong-phai-cay-nhi-phan">
     8.5.2. Trường hợp không phải cây nhị phân
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chi-so-gini">
   8.6. Chỉ số Gini
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cay-quyet-dinh-cho-bai-toan-du-bao">
   8.7. Cây quyết định cho bài toán dự báo
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dieu-kien-dung-de-giam-qua-khop-overfitting">
   8.8. Điều kiện dừng để giảm quá khớp (
   <em>
    overfitting
   </em>
   )
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cat-tia-pruning">
   8.9. Cắt tỉa  (
   <em>
    pruning
   </em>
   )
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tuning-sieu-tham-so-cho-mo-hinh-cay-quyet-dinh">
   8.10. Tuning siêu tham số cho mô hình cây quyết định
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bai-tap">
   8.11. Bài tập
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tai-lieu-tham-khao">
   8. 12. Tài liệu tham khảo
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="mo-hinh-cay-quyet-dinh-decision-tree">
<h1>8.1. Mô hình cây quyết định (<em>decision tree</em>)<a class="headerlink" href="#mo-hinh-cay-quyet-dinh-decision-tree" title="Permalink to this headline">¶</a></h1>
<p>Mô hình <em>cây quyết định</em> là một mô hình được sử dụng khá phổ biến và hiệu quả trong cả hai lớp bài toán phân loại và dự báo của học có giám sát. Khác với những thuật toán khác trong học có giám sát, mô hình <em>cây quyết định</em> không tồn tại phương trình dự báo. Mọi việc chúng ta cần thực hiện đó là tìm ra một cây quyết định dự báo tốt trên tập huấn luyện và sử dụng cây quyết định này dự báo trên tập kiểm tra.</p>
<p>Vậy một cây quyết định sẽ được xây dựng như thế nào? Điều gì ẩn chứa sau thuật toán cây quyết định? Để trả lời cho câu hỏi này, chúng ta cùng lấy ví dụ về áp dụng mô hình cây quyết định cho bài toán phân loại giá nhà trên bộ dữ liệu boston.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="bai-toan-phan-loai-cay-quyet-dinh-tren-bo-du-lieu-boston">
<h1>8.2. Bài toán phân loại cây quyết định trên bộ dữ liệu boston<a class="headerlink" href="#bai-toan-phan-loai-cay-quyet-dinh-tren-bo-du-lieu-boston" title="Permalink to this headline">¶</a></h1>
<p>Bộ dữ liệu được sử dụng cho bài toán này là bộ dữ liệu về giá nhà ở ở boston bao gồm 13 quan sát và 506 biến.</p>
<p>Đọc dữ liệu:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">boston</span><span class="o">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">price</span> <span class="o">&gt;</span> <span class="mi">20</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">price</span> <span class="ow">in</span> <span class="n">y</span><span class="p">]</span> <span class="c1"># 1 nhà giá cao, 0 nhà giá thấp</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input features: &#39;</span><span class="p">,</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input features:  CRIM, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B, LSTAT
(506, 13)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/khanh/miniconda3/envs/deepai-book/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.

    The Boston housing prices dataset has an ethical problem. You can refer to
    the documentation of this function for further details.

    The scikit-learn maintainers therefore strongly discourage the use of this
    dataset unless the purpose of the code is to study and educate about
    ethical issues in data science and machine learning.

    In this special case, you can fetch the dataset from the original
    source::

        import pandas as pd
        import numpy as np


        data_url = &quot;http://lib.stat.cmu.edu/datasets/boston&quot;
        raw_df = pd.read_csv(data_url, sep=&quot;\s+&quot;, skiprows=22, header=None)
        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
        target = raw_df.values[1::2, 2]

    Alternative datasets include the California housing dataset (i.e.
    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing
    dataset. You can load the datasets as follows::

        from sklearn.datasets import fetch_california_housing
        housing = fetch_california_housing()

    for the California housing dataset and::

        from sklearn.datasets import fetch_openml
        housing = fetch_openml(name=&quot;house_prices&quot;, as_frame=True)

    for the Ames housing dataset.
    
  warnings.warn(msg, category=FutureWarning)
</pre></div>
</div>
</div>
</div>
<p>Ý nghĩa của những trường dữ liệu:</p>
<p>Các biến đầu vào:</p>
<ul class="simple">
<li><p>crim: Tỷ lệ phạm tội phạm bình quân đầu người theo thị trấn.</p></li>
<li><p>zn: Tỷ lệ đất ở được quy hoạch cho các lô trên 25.000 foot square.</p></li>
<li><p>indus: Tỷ lệ diện tích thuộc lĩnh vực kinh doanh phi bán lẻ trên mỗi thị trấn.</p></li>
<li><p>chas: Biến giả, = 1 nếu được bao bởi sông Charles River, = 0 nếu ngược lại.</p></li>
<li><p>nox: Nồng độ khí Ni-tơ oxit.</p></li>
<li><p>rm: Trung bình số phòng trên một căn hộ.</p></li>
<li><p>age: Tỷ lệ căn hộ được xây dựng trước năm 1940.</p></li>
<li><p>dis: Khoảng cách trung bình có trọng số tới 5 trung tâm việc làm lớn nhất ở Boston.</p></li>
<li><p>rad: Chỉ số về khả năng tiếp cận đường cao tốc.</p></li>
<li><p>tax: Giá trị thuế suất tính trên đơn vị 10000$.</p></li>
<li><p>ptratio: Tỷ lệ học sinh-giáo viên trên mỗi thị trấn.</p></li>
<li><p>black: Tỷ lệ số người da đen trong thị trấn được tính theo công thức: 1000(Bk−0.63)2 ở đây Bk là tỷ lệ người da đen trong thị trấn.</p></li>
<li><p>lstat: Tỷ lệ phần trăm dân số thu nhập thấp.</p></li>
</ul>
<p>Biến mục tiêu: Căn cứ vào giá nhà ở &gt; 20 nghìn USD hoặc nhỏ hơn mà chúng ta phân thành nhãn 1 (giá cao) và nhãn 0 (giá thấp).</p>
<p>Tiếp theo ta sẽ xây dựng một mô hình phân loại dự trên cây quyết định với độ sâu tối đa là 3. Độ sâu ở đây chính là số lượng tối đa các câu hỏi khi đi từ <em>node gốc</em> tới <em>node lá</em>. Chúng ta khai báo độ sâu thông qua đối số <em>max_depth</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="n">tree_clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">tree_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DecisionTreeClassifier(max_depth=3)
</pre></div>
</div>
</div>
</div>
<p>Tiếp theo là sử dụng hàm <code class="docutils literal notranslate"><span class="pre">export_graphviz()</span></code> để biểu đồ hoá cây quyết định. Trong hàm này chúng ta chỉ cần truyền vào mô hình, tên các đặc trưng đầu vào thông qua đối số <code class="docutils literal notranslate"><span class="pre">feature_names</span></code> và các nhãn thông qua đối số <code class="docutils literal notranslate"><span class="pre">class_names</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">graphviz</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>

<span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">tree_clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                                <span class="n">feature_names</span><span class="o">=</span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span>  
                                <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;low&#39;</span><span class="p">,</span> <span class="s1">&#39;high&#39;</span><span class="p">],</span>
                                <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_data</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;png&quot;</span><span class="p">)</span>
<span class="n">graph</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_10642</span><span class="o">/</span><span class="mf">2901286609.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">graphviz</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> 
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">dot_data</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">tree_clf</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
<span class="g g-Whitespace">      </span><span class="mi">5</span>                                 <span class="n">feature_names</span><span class="o">=</span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;graphviz&#39;
</pre></div>
</div>
</div>
</div>
<p><strong>Cách dự báo từ cây quyết định?</strong></p>
<p>Từ cây quyết định ở trên, dựa trên việc rẽ nhánh, chúng ta suy ra được nhãn dự báo cho các quan sát. Giả sử quan sát đầu vào có giá trị: <code class="docutils literal notranslate"><span class="pre">LSTAT</span> <span class="pre">=</span> <span class="pre">10,</span> <span class="pre">RM</span> <span class="pre">=</span> <span class="pre">6,</span> <span class="pre">DIS</span> <span class="pre">=</span> <span class="pre">3</span></code>. Khi đó xuất phát từ <em>node gốc</em> ta tuần tự đặt và trả lời các câu hỏi:</p>
<ul class="simple">
<li><p>LSTAT &lt;= 14.115 là đúng, như vậy tại <em>node gốc</em> ta rẽ sang nhánh True bên trái.</p></li>
<li><p>Tiếp theo ta lại xét tiếp câu hỏi RM &lt;= 6.034, kết quả trả về là True. Do đó ta lại rẽ sang nhánh bên trái.</p></li>
<li><p>Tiếp theo xét tiếp câu hỏi DIS &lt;= 4.714, kết quả trả về tiếp tục là True. Do đó ta rẽ sang bên trái và thu được kết quả dự báo ở <em>node lá</em> là nhãn high.</p></li>
</ul>
<p>Để minh chứng cho nhận định trên, ta sẽ thử nghiệm dự báo cho 5 quan sát sao cho giá trị <code class="docutils literal notranslate"><span class="pre">LSTAT</span> <span class="pre">=</span> <span class="pre">10,</span> <span class="pre">RM</span> <span class="pre">=</span> <span class="pre">6,</span> <span class="pre">DIS</span> <span class="pre">=</span> <span class="pre">3</span></code> là cố định và những giá trị khác thay đổi ngẫu nhiên và kiểm tra kết quả dự báo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># LSTAT = 10, RM = 6, DIS = 3, các giá trị khác có thể thay đổi tuỳ ý</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
  <span class="n">CRIM</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">INDUS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">ZN</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">CHAS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">NOX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">AGE</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">RAD</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">TAX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">PTRATIO</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

  <span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;CRIM&#39;</span><span class="p">:</span><span class="n">CRIM</span><span class="p">,</span> <span class="s1">&#39;ZN&#39;</span><span class="p">:</span><span class="n">ZN</span><span class="p">,</span> <span class="s1">&#39;INDUS&#39;</span><span class="p">:</span><span class="n">INDUS</span><span class="p">,</span> <span class="s1">&#39;CHAS&#39;</span><span class="p">:</span><span class="n">CHAS</span><span class="p">,</span> <span class="s1">&#39;NOX&#39;</span><span class="p">:</span><span class="n">NOX</span><span class="p">,</span> <span class="s1">&#39;RM&#39;</span><span class="p">:[</span><span class="mi">6</span><span class="p">],</span> <span class="s1">&#39;AGE&#39;</span><span class="p">:</span><span class="n">AGE</span><span class="p">,</span> <span class="s1">&#39;DIS&#39;</span><span class="p">:[</span><span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;RAD&#39;</span><span class="p">:</span><span class="n">RAD</span><span class="p">,</span> <span class="s1">&#39;TAX&#39;</span><span class="p">:</span><span class="n">TAX</span><span class="p">,</span> <span class="s1">&#39;PTRATIO&#39;</span><span class="p">:</span><span class="n">PTRATIO</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">:</span><span class="n">B</span><span class="p">,</span> <span class="s1">&#39;LSTAT&#39;</span><span class="p">:[</span><span class="mi">10</span><span class="p">]})</span>
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">tree_clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;probability low </span><span class="si">{}</span><span class="s1">, high </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predicted label </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p>Chúng ta thấy dù có thay đổi các giá trị khác như thế nào, miễn là 3 giá trị <code class="docutils literal notranslate"><span class="pre">LSTAT</span> <span class="pre">=</span> <span class="pre">10,</span> <span class="pre">RM</span> <span class="pre">=</span> <span class="pre">6,</span> <span class="pre">DIS</span> <span class="pre">=</span> <span class="pre">3</span></code> thoả mãn thì chúng ta đều thu được dự báo có nhãn là 1. Điều này cho thấy dự báo từ cây nhị phân đã tuân theo qui luật rẽ nhánh in đậm như bên dưới:</p>
<p><img alt="" src="https://imgur.com/V8Gyi63.png" /></p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="duong-bien-phan-chia-cua-cay-quyet-dinh">
<h1>8.3. Đường biên phân chia của cây quyết định<a class="headerlink" href="#duong-bien-phan-chia-cua-cay-quyet-dinh" title="Permalink to this headline">¶</a></h1>
<p>Đường biên phân chia của cây quyết định sẽ dựa trên kịch bản rẽ nhánh mà chúng ta lựa chọn. Gỉa định chúng ta đi từ node <code class="docutils literal notranslate"><span class="pre">(LSTAT</span> <span class="pre">&lt;=</span> <span class="pre">14.115)</span> <span class="pre">--&gt;</span> <span class="pre">(RM</span> <span class="pre">&lt;=</span> <span class="pre">6.034)</span> <span class="pre">--&gt;</span> <span class="pre">(DIS</span> <span class="pre">&lt;=</span> <span class="pre">4.714)</span></code>. Khi đó đường biên phân chia là những đường thẳng trong hình bên dưới đi qua ngưỡng threshold.</p>
<p><img alt="" src="https://i.imgur.com/8qAE60t.jpeg" /></p>
<ul class="simple">
<li><p>Bước 1: Đường thẳng <span class="math notranslate nohighlight">\(x = 14.115\)</span> sẽ phân mặt phẳng thành 2 phần là <span class="math notranslate nohighlight">\(x \leq 14.115\)</span> và <span class="math notranslate nohighlight">\(x &gt; 14.115\)</span>. Theo phương án rẽ nhánh tại <em>node gốc</em> tương ứng với biến <code class="docutils literal notranslate"><span class="pre">LSTAT</span></code>, chúng ta lựa chọn nửa mặt phẳng <span class="math notranslate nohighlight">\(x \leq 14.115\)</span> nằm bên trái để dự báo nhãn.</p></li>
<li><p>Bước 2: Đối với nửa mặt phẳng <span class="math notranslate nohighlight">\(x \leq 14.115\)</span> chúng ta lại xét tiếp trục y tương ứng với biến <code class="docutils literal notranslate"><span class="pre">RM</span></code>. Đường thẳng <span class="math notranslate nohighlight">\(y = 6.034\)</span> sẽ tiếp tục chia nửa mặt phẳng này thành hai phần là <span class="math notranslate nohighlight">\(y &gt; 6.034\)</span> và <span class="math notranslate nohighlight">\(y \leq 6.034\)</span>. Theo kịch bản chúng ta sẽ lựa chọn hình chữ nhật bị giới hạn bởi <span class="math notranslate nohighlight">\(x \geq 14.115\)</span> và <span class="math notranslate nohighlight">\(y \geq 6.034\)</span>. Lúc này cây quyết định vẫn chưa kết thúc. Do mô hình có độ sâu là 3 nên chúng ta phải tiếp tục phân chia tiếp theo threshold của biến <code class="docutils literal notranslate"><span class="pre">DIS</span></code>.</p></li>
<li><p>Đường thẳng <span class="math notranslate nohighlight">\(x = 4.714\)</span> sẽ tiếp tục phân chia hình chữ nhật thu được ở bước 2 thành hai hình chữ nhật con. Ta chỉ lấy hình chữ nhật nằm bên trái. Đó chính là hình chữ nhật bị giới hạn bởi các cạnh in đậm.</p></li>
</ul>
<p>Chúng ta để ý thấy rằng mọi điểm nằm trong hình chữ nhật có các cạnh in đậm sẽ cùng được dự báo thuộc về nhóm <code class="docutils literal notranslate"><span class="pre">high</span></code> hình tròn như hình vẽ. Các cạnh in đậm của hình chữ nhật chính là đường biên phân chia của cây quyết định. Đối với những điểm nằm ngoài hình chữ nhật này thì có thể lẫn cả nhãn <code class="docutils literal notranslate"><span class="pre">high</span></code> và nhãn <code class="docutils literal notranslate"><span class="pre">low</span></code> và chúng ta cần những kịch bản rẽ nhánh khác để dự báo nhãn cho chúng.</p>
<p>Như vậy đường biên phân chia của cây quyết định là khá đơn giản và trực quan. Chúng ta không cần giải bài toán tối ưu như SVM hay Logistic để tìm ra được đường biên phân chia này mà đơn thuần chúng chỉ là một siêu phẳng đi qua một ngưỡng threshold cố định. Những mô hình có đường biên phân chia có thể giải thích được như vậy được gọi là <em>white box models</em>. Trái lại, trong machine learning tồn tại những mô hình mà chúng ta không thể giải thích được vì sao mô hình lại đưa ra quyết định như vậy. Chẳng hạn như trong mạng nơ ron, mô hình có thể dễ dàng dự báo một bức ảnh là chó hay mèo nhưng ta không thể nói được vì sao mô hình lại dự báo đó là chó hoặc mèo. Kết quả dự báo căn cứ vào bao nhiêu phần trăm quyết định được đưa ra dựa trên các đặc trưng như lông, đuôi, mắt, mũi, miệng của chúng? Những mô hình như vậy được gọi là <em>black box models</em>.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="cach-khoi-tao-cay-quyet-dinh">
<h1>8.4. Cách khởi tạo cây quyết định<a class="headerlink" href="#cach-khoi-tao-cay-quyet-dinh" title="Permalink to this headline">¶</a></h1>
<p>Để trả lời cho câu hỏi một cây quyết định được tạo ra như thế nào? Chúng ta cần biết được <strong>thứ tự câu hỏi</strong> là gì và <strong>cách đặt câu hỏi</strong> như thế nào?</p>
<p><strong>Thứ tự lựa chọn câu hỏi</strong></p>
<p>Đối với những bộ dữ liệu có số lượng biến đầu vào <span class="math notranslate nohighlight">\(d\)</span> lớn, việc lựa chọn biến nào sẽ được đặt ở <em>node gốc</em> là điều không dễ dàng. Một kịch bản lựa chọn ngẫu nhiên chỉ có xác suất đúng là <span class="math notranslate nohighlight">\(\frac{1}{d}\)</span> và dường như khả năng chúng ta chọn sai là rất cao. Do đó chúng ta cần phải có một tiêu chí nào đó để lựa chọn biến phù hợp. Xuất phát từ yêu cầu này, chúng ta hình thành nên các độ đo như <em>entropy, Gini</em> đo lường mức độ tinh khiến (<em>purity</em>) và vẩn đục (<em>impurity</em>) của một biến mà ta sẽ tìm hiểu bên dưới.</p>
<div class="section" id="tinh-khiet-va-van-duc">
<h2>8.4.1. Tinh khiết và vẩn đục<a class="headerlink" href="#tinh-khiet-va-van-duc" title="Permalink to this headline">¶</a></h2>
<p>Giả định chúng ta đang xây dựng một cây quyết định mà tại một <em>node quyết định</em> chúng ta có 50 quan sát rơi vào chúng. Có ba phương án lựa chọn node lá tiếp theo tương ứng với 3 biến, chúng có kết quả thống kê tại <em>node lá</em> lần lượt là:</p>
<ul class="simple">
<li><p>Biến 1: 25 nhãn 1, 25 nhãn 0.</p></li>
<li><p>Biến 2: 20 nhãn 1, 30 nhãn 0.</p></li>
<li><p>Biến 3: 0 nhãn 1, 50 nhãn 0.</p></li>
</ul>
<p>Theo bạn đâu sẽ là biến phù hợp nhất được lựa chọn tại node lá?</p>
<p>Kịch bản lựa chọn biến 1 dường như là vô nghĩa vì nó tương đương với dự báo ngẫu nhiên nhãn 0 và 1.</p>
<p>Kịch bản tương ứng với biến 2 có xu hướng dự báo thiên về nhãn 0 nhưng tỷ lệ dự báo sai nhãn 1 vẫn còn cao.</p>
<p>Lựa chọn biến 3 là tuyệt vời vì chúng ta đã dự báo đúng hoàn toàn nhãn 0.</p>
<p>Như vậy mục tiêu của chúng ta khi đối diện với việc phân loại đó là kết quả trả về tại <em>node lá</em> chỉ thuộc về một lớp. Chúng ta sử dụng một thuật ngữ ngắn gọn để gọi tên trường hợp này là <em>tinh khiết</em> (<em>purity</em>). Trái ngược lại với <em>tinh khiết</em> sẽ là khái niệm <em>vấn đục</em> (<em>impurity</em>), tức phân phối của các nhãn tại node lá còn khá mập mờ, không có xu hướng thiên về một nhãn nào cụ thể. Nếu ra quyết định phân loại dựa trên kịch bản dẫn tới node lá sẽ trả về kết quả không đáng tin cậy.</p>
</div>
<div class="section" id="thuoc-do-cho-muc-do-tinh-khiet-purity">
<h2>8.4.2. Thước đo cho mức độ <em>tinh khiết</em> (<em>purity</em>)<a class="headerlink" href="#thuoc-do-cho-muc-do-tinh-khiet-purity" title="Permalink to this headline">¶</a></h2>
<p><em>Entropy</em> là một khái niệm khoa học được sử dụng lần đầu tiên trong nhiệt động lực học và sau đó được phổ biến trong các lĩnh vực khác như vật lý, hoá học, y sinh, lý thuyết thông tin,… Trong nhiệt động lực học thì Entropy là một đặc tính vật lý có thể đo lường được có sự liên kết với trạng thái hỗn loạn (<em>disorder</em>) hoặc không chắc chắn (<em>uncertainty</em>).</p>
<p>Trong thuật toán <em>cây quyết định</em> chúng ta sẽ sử dụng <em>Entropy</em> để đánh giá mức độ <em>tinh khiết</em> của phân phối xác suất của một sự kiện.</p>
<p>Giả sử một sự kiện xảy ra với phân phối xác suất là <span class="math notranslate nohighlight">\(\mathbf{p} = (p_1, p_2, \dots, p_C)\)</span> thoả mãn <span class="math notranslate nohighlight">\(\sum_{i=1}^{C} p_i = 1\)</span>. Khi đó hàm <em>entropy</em> đối với sự kiện trên là:</p>
<div class="math notranslate nohighlight">
\[\mathbf{H}(\mathbf{p}) = -\sum_{i=1}^{C}p_i \log p_i  \tag{1}\]</div>
<p>Trong trường hợp <span class="math notranslate nohighlight">\(p_i = 0\)</span> thì hàm <em>entropy</em> là không xác định do <span class="math notranslate nohighlight">\(\log p_i\)</span> không tồn tại, tuy nhiên căn cứ vào giá trị hội tụ thì chúng ta sẽ qui ước giá trị của <em>entropy</em> trong trường hợp này là 0.</p>
<p>Trong lý thuyết thông tin thì hàm <span class="math notranslate nohighlight">\(\log\)</span> ở phương trình <span class="math notranslate nohighlight">\((1)\)</span> là hàm logarith với cơ số 2. Tuy nhiên ở đây chúng ta có thể sử dụng hàm logarith cơ số tự nhiên <span class="math notranslate nohighlight">\(e\)</span> mà không thay đổi bản chất do giá trị đạt được tương đương với việc nhân với một hằng số.</p>
<p>Khảo sát hàm <em>entropy</em> chúng ta sẽ nhận thấy đây là một hàm không âm có giá trị tối đa đạt được khi phân phối xác suất là đồng đều trên toàn bộ các nhãn. Để đơn giản bên dưới chúng ta vẽ đồ thị và khảo sát hàm <em>entropy</em> đối với bài toán phân loại nhị phân.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Tính entropy theo p</span>
<span class="k">def</span> <span class="nf">_entropy</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
  <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">p</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">+</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)))</span>

<span class="c1"># Khởi tạo gía trị yhat từ 0 đến 1</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>

<span class="c1"># Hàm visualize cross entropy</span>
<span class="k">def</span> <span class="nf">_plot_crs</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
  <span class="n">entropy</span> <span class="o">=</span> <span class="n">_entropy</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">entropy</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;entropy&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Entropy&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">_plot_crs</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Giá trị lớn nhất đạt được khi <span class="math notranslate nohighlight">\(p_0 = p_1 = \frac{1}{2}\)</span>. Trong khi giá trị nhỏ nhất đạt được khi một trong hai xác suất bằng 1 và xác suất còn lại bằng 0.</p>
<p><strong>Bên dưới là lời giải cho bài toán cực trị entropy cho bạn nào thực sự quan tâm</strong></p>
<p>Ta dễ dàng tìm được cực trị <span class="math notranslate nohighlight">\(\mathbf{H}(\mathbf{p})\)</span>. Thật vậy, vì <span class="math notranslate nohighlight">\(1 \geq p_i \geq 0\)</span> nên giá trị <span class="math notranslate nohighlight">\(\mathbf{H}(\mathbf{p}) \geq 0\)</span> là hiển nhiên. Đẳng thức xảy ra khi tồn tại một giá trị <span class="math notranslate nohighlight">\(p_i = 1\)</span> và các giá trị còn lại bằng 0.</p>
<p>Để tìm cực đại chúng ta xét hàm <span class="math notranslate nohighlight">\(f(x) = -x\log{x}\)</span>. Hàm này có đạo hàm bậc 2 là <span class="math notranslate nohighlight">\(f''(x) = \frac{-1}{x} \leq 0\)</span> nên là một hàm lõm trên khoảng <span class="math notranslate nohighlight">\((0, 1]\)</span>. Áp dụng bất đẳng thức Jensen ta có:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{H}(\mathbf{p}) = \sum_{i=1}^C f(p_1) \leq  C f(\frac{\sum_{i=1}^C p_i}{C}) = C f(\frac{1}{C}) = C [-\frac{1}{C}\log \frac{1}{C}] = \log C
\]</div>
<p>Đẳng thức xảy ra khi <span class="math notranslate nohighlight">\(p_0=p_1= \dots =p_C=\frac{1}{C}\)</span>.</p>
<p>Kết luận giá trị <em>entropy</em> cực tiểu đạt được khi phân phối <span class="math notranslate nohighlight">\(\mathbf{p}\)</span> là tinh khiết nhất, tức phân phối hoàn toàn thuộc về một nhóm. Trái lại, <em>entropy</em> cực đại đạt được khi toàn bộ xác suất thuộc về các nhóm là bằng nhau. Một phân phối có <em>entropy</em> càng cao thì mức độ tinh khiết của phân phối đó sẽ càng thấp và ngược lại.</p>
<p>Như vậy về bản chất thì <em>entropy</em> là một thước đo về độ tinh khiết của phân phối xác suất. Dựa trên <em>entropy</em> chúng ta có thể đánh giá tính hiệu quả của câu hỏi ở mỗi node và quyết định xem đâu là câu hỏi hiệu quả hơn (có độ tinh khiết lớn hơn, <em>entropy</em> nhỏ hơn). Tiếp theo chúng ta sẽ cùng tìm hiểu giải thuật tìm kiếm <em>tham lam</em> (<em>greedy</em>) theo chiều từ trên xuống để xây dựng nên cây quyết định dựa trên hàm <em>entropy</em>.</p>
</div>
<div class="section" id="tim-kiem-tham-lam-va-truy-hoi">
<h2>8.4.3. Tìm kiếm tham lam và truy hồi<a class="headerlink" href="#tim-kiem-tham-lam-va-truy-hoi" title="Permalink to this headline">¶</a></h2>
<p>Giả sử số lượng biến của bạn là <span class="math notranslate nohighlight">\(n\)</span> rất lớn. Bạn muốn tạo ra một cây nhị phân với độ sâu tối đa là <span class="math notranslate nohighlight">\(d\)</span>. Số khả năng lựa chọn <span class="math notranslate nohighlight">\(d\)</span> biến (có xét đến tính thứ tự) từ <span class="math notranslate nohighlight">\(m\)</span> biến để tạo thành một cây nhị phân là chỉnh hợp <span class="math notranslate nohighlight">\(A_n^d = \frac{d!}{(d-n)!}\)</span>. Khi <span class="math notranslate nohighlight">\(d\)</span> lớn thì đây là một con số rất lớn. Do đó rất khó để chúng ta tìm được đúng cây nhị phân tối ưu ngay chỉ trong một lần. Thay vào đó, một chiến lược hợp lý và khôn ngoan hơn là đi từng bước nhỏ và tìm cách lựa chọn câu hỏi tối ưu ở mỗi node. Chiến lược như vậy được gọi là <em>tìm kiếm tham lam</em>.</p>
<p>Ngoài ra quá trình lựa chọn này sẽ tiếp diễn một cách truy hồi (<em>recursive</em>) theo chiều từ trên xuống dưới cho đến khi đạt ngưỡng về độ sâu hoặc node cuối cùng hoàn toàn thuộc về một nhóm. Ở một số thuật toán, để hạn chế hiện tượng <em>quá khớp</em> chúng ta có thể dừng phân chia nếu chạm ngưỡng số lượng quan sát tối thiểu ở node lá hoặc giới hạn về độ sâu của nhánh (chúng ta sẽ làm rõ hơn điều này ở phần bên dưới).</p>
<p>Cách xây dựng cây quyết định theo phương pháp tìm kiếm tham lam và truy hồi dựa trên thuật toán ID3 mà ta sẽ tìm hiểu bên dưới.</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="thuat-toan-id3-va-cart">
<h1>8.5. Thuật toán ID3 và CART<a class="headerlink" href="#thuat-toan-id3-va-cart" title="Permalink to this headline">¶</a></h1>
<p>Thuật toán ID3 (viết tắt của <em>Iterative Dichotomiser 3</em>) là một giải thuật khá lâu đời được tạo ra bởi <code class="docutils literal notranslate"><span class="pre">Ross</span> <span class="pre">Quinlan</span></code> nhằm xây dựng cây quyết định phù hợp từ một bộ dữ liệu. Đây là giải thuật tiền đề mà dựa trên cơ sở đó, rất nhiều những giải thuật khác liên quan tới cây quyết định được kế thừa và phá triển:</p>
<ul class="simple">
<li><p>C4.5: Kế thừa của thuật toán ID3. Giải thuật này được sử dụng phổ biến trong machine learning và xử lý ngôn ngữ tự nhiên.</p></li>
<li><p>CART: Viết tắt của cụm từ <em>Classification And Regression Tree</em>. Ưu điểm của nó là có thể sử dụng cho cả bài toán phân loại và hồi qui.</p></li>
<li><p>CHAID: Sử dụng phân phối <span class="math notranslate nohighlight">\(\chi^2\)</span> để tự động tương tác phát hiện phân chia  khi tính toán cây phân loại.</p></li>
<li><p>MARS: Áp dụng hồi qui đa biến theo splines. Đây là một phương pháp hồi qui chia để trị, có thể loại bỏ ảnh hưởng của outliers.</p></li>
</ul>
<p>Trong khuôn khổ bài viết này chúng ta sẽ tìm hiểu về thuật toán CART. Đây là thuật toán được sử dụng phổ biến nhất trong machine learning và có thể được sử dụng trong cả hai bài toán phân loại và hồi qui.</p>
<div class="section" id="truong-hop-cay-nhi-phan-voi-bien-lien-tuc">
<h2>8.5.1. Trường hợp cây nhị phân với biến liên tục<a class="headerlink" href="#truong-hop-cay-nhi-phan-voi-bien-lien-tuc" title="Permalink to this headline">¶</a></h2>
<p>Giả định chúng ta đang đứng ở node lá bất kỳ, các quan sát tại node này là tập <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> có kích thước <span class="math notranslate nohighlight">\(|\mathcal{S}|=N\)</span>. Tại node lá này thì mức độ tinh khiết được đánh giá thông qua hàm <em>entropy</em> được tính theo công thức:</p>
<div class="math notranslate nohighlight">
\[\mathbf{H}(\mathcal{S}) = - \sum_{i=1}^C p_i \log(p_i)\]</div>
<p>Trong đó <span class="math notranslate nohighlight">\(p_i\)</span> là tỷ lệ phần trăm các quán sát thuộc về nhãn <span class="math notranslate nohighlight">\(i\)</span>. Lưu ý nhãn dự báo tại node lá trùng với nhãn mà có tỷ lệ lớn nhất.</p>
<p>Trong thuật toán CART, <em>hàm mất mát</em> được định nghĩa là tổng có trọng số của <em>entropy</em> trên toàn bộ các <em>node lá</em>. Trọng số ở đây được lấy theo tỷ lệ phần trăm quan sát trên từng <em>node lá</em>. Điều đó có nghĩa rằng với những <em>node lá</em> có số lượng quan sát lớn thì ảnh hưởng của nó lên hàm mất mát là lớn hơn so với những <em>node lá</em> có số lượng quan sát nhỏ. Nhận định này là hợp lý vì việc phân loại sai những node lá lớn gây hậu quả nghiêm trọng hơn so với phân loại sai node nhỏ. Để tối thiểu hoá <em>hàm mất mát</em> thì chúng ta phải lựa chọn biến và ngưỡng sao cho tổng giá trị của <em>hàm mất mát</em> là nhỏ nhất.</p>
<p>Tại node hiện tại, một câu hỏi đặt ra là liệu tiếp tục phân chia thì có tốt hơn không? Tốt hơn được thể hiện thông qua giá trị entropy phải giảm nhiều nhất. Nếu tốt hơn thì chúng ta phải lựa chọn biến nào tiếp theo? nếu là biến liên tục thì lựa chọn ngưỡng phân chia như thế nào?</p>
<p>Lưu ý trong thuật toán ID3 thì chúng ta chỉ áp dụng trên các biến phân loại (<em>category</em>). Thuật toán CART cho phép ta tuning threshold để biến đổi biến liên tục sang các đặc trưng (<em>features</em>). Chẳng hạn biến được lựa chọn là <span class="math notranslate nohighlight">\(x^{(j)}\)</span> có ngưỡng phân chia là <span class="math notranslate nohighlight">\(t\)</span> thì hai <em>đặc trưng</em> tương ứng là <span class="math notranslate nohighlight">\(x^{(j)} &gt; t\)</span> và <span class="math notranslate nohighlight">\(x^{(j)} \leq t\)</span>. Ngưỡng <span class="math notranslate nohighlight">\(t\)</span> giúp phân loại tập <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> thành hai tập con tương ứng là:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{split}
\left\{
\begin{matrix}
\mathcal{S}_0 = \{ \mathbf{x}_i | x_{i}^{(j)} \leq t, \mathbf{x}_i \in \mathcal{S} \} \\
\mathcal{S}_1 = \{ \mathbf{x}_i | x_{i}^{(j)} &gt; t, \mathbf{x}_i \in \mathcal{S} \}\end{matrix}
\right.\end{split}
\end{split}\]</div>
<p>Trong đó <span class="math notranslate nohighlight">\(\mathbf{x}_i \in \mathbb{R}^{m}\)</span> là quan sát thứ <span class="math notranslate nohighlight">\(i\)</span> của tập <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. Quan sát này bao gồm <span class="math notranslate nohighlight">\(m\)</span> chiều tương ứng với số lượng biến đầu vào. <span class="math notranslate nohighlight">\(x_{i}^{(j)}\)</span> là quan sát thứ <span class="math notranslate nohighlight">\(i\)</span> của biến <span class="math notranslate nohighlight">\(x^{(j)}\)</span>. Giả sử <span class="math notranslate nohighlight">\(N_0 = |\mathcal{S}_0|\)</span> và <span class="math notranslate nohighlight">\(N_1 = |\mathcal{S}_1|\)</span>. Do hai tập con <span class="math notranslate nohighlight">\(\mathcal{S}_1, \mathcal{S}_0\)</span> là không giao nhau nên <span class="math notranslate nohighlight">\(N = N_0 + N_1\)</span>.</p>
<p><strong>Làm sao để lựa chọn được ngưỡng t tốt nhất?</strong></p>
<p>Kịch bản phân chia trên giúp tạo thành hai node lá. Mức độ tinh khiết sau phân chia sẽ bằng tổng có trọng số của <em>entropy</em> tại mỗi node lá mới. Giá trị này được gọi là <em>entropy</em> sau phân chia:</p>
<div class="math notranslate nohighlight">
\[\mathbf{H}(x^{(j)}, t; \mathcal{S}) = \frac{N_0}{N}\mathbf{H}(\mathcal{S}_0) + \frac{N_1}{N} \mathbf{H}(\mathcal{S}_1)\]</div>
<p>Ngưỡng <span class="math notranslate nohighlight">\(t\)</span> sẽ được tuning trong miền xác định của biến <span class="math notranslate nohighlight">\(x^{(j)}\)</span> sao cho <em>entropy</em> sau phân chia đạt được là nhỏ nhất. Điều này cũng đồng nghĩa với mức độ tinh khiết thu được tại node lá là tinh khiết nhất. Đối với biến <em>phân loại</em> thì chúng ta không cần phải tuning ngưỡng mà có thể trực tiếp tính ngay <em>entropy</em>.</p>
<p>Một kịch bản phân chia được coi là mang lại kết quả tối hơn so với không phân chia nếu như kết quả sau phân chia giúp gia tăng độ tinh khiết. Tức là giá trị <em>entropy</em> <strong>trước phân chia</strong> so với <strong>sau phân chia</strong> là giảm và đồng thời chúng ta muốn mức độ giảm này là tối đa để mức độ tinh khiết đạt được cải thiện nhiều nhất. Giá trị <em>entropy</em> giảm chính là lượng thông tin mà ta biết thêm, giúp ích cho việc phân loại, chúng ta định nghĩa chúng dưới dạng một hàm số mới gọi là <em>hàm tin thu</em> (<em>information gain</em>):</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\mathbf{G}(x^{(j)}, t; \mathcal{S}) &amp; = &amp; \mathbf{H}(\mathcal{S}) - \mathbf{H}(x^{(j)}, t; \mathcal{S}) \\
&amp; = &amp; \mathbf{H}(\mathcal{S}) - \frac{N_0}{N}\mathbf{H}(\mathcal{S}_0) - \frac{N_1}{N} \mathbf{H}(\mathcal{S}_1)\end{eqnarray}\end{split}\]</div>
<p>Ở mỗi lượt, giải thuật <em>tìm kiếm tham lam</em> sẽ tìm kiếm theo thứ tự <em>từ trên xuống dưới</em> biến <span class="math notranslate nohighlight">\(x^{(j)}\)</span> và ngưỡng <span class="math notranslate nohighlight">\(t\)</span> tương ứng, sao cho giá trị <em>hàm tin thu</em> đạt cực đại. Tức là <span class="math notranslate nohighlight">\(j, t\)</span> là nghiệm của bài toán tối ưu:</p>
<div class="math notranslate nohighlight">
\[\hat{j}, \hat{t}  = \arg \max_{j, t} \mathbf{G}(x^{(j)}, t; \mathcal{S}) \]</div>
<p>Như vậy chiến lược lựa chọn của thuật toán CART tại mỗi bước đó là tìm ra biến và ngưỡng phân chia mà <em>hàm tin thu</em> là lớn nhất. Các sự việc xảy ra trước khi quyết định phân chia tiếp được xem như là sự đã rồi và chúng ta không thay đổi được. Chính vì thế có thể coi <em>entropy</em> trước phân chia <span class="math notranslate nohighlight">\(\mathbf{H}(\mathcal{S})\)</span> là không đổi. Khi đó giá trị <strong>tối đa</strong> của <em>hàm tin thu</em> đạt được tương đương với giá trị của <em>entropy</em> sau phân chia là <strong>tối thiểu</strong>. Điều này đồng nghĩa với chúng ta có thể lựa chọn câu hỏi để <em>hàm tin thu</em> hoặc <em>entropy</em> sau phân chia là lớn nhất.</p>
<p>Giá trị dự báo cho các quan sát thuộc về một node lá sẽ chính là nhãn có xác suất xảy ra là lớn nhất.</p>
<p><strong>Bài tập:</strong> Cho bảng số liệu dự báo khả năng mưa (<em>rain</em>) dựa trên các thông tin đầu vào gồm: có mây (<em>cloudy</em>), có nắng (<em>sunny</em>), có gió (<em>windy</em>):</p>
<p><img alt="" src="https://imgur.com/UN5IdXn.png" /></p>
<ol class="simple">
<li><p>Nếu <em>node gốc</em> là <code class="docutils literal notranslate"><span class="pre">windy</span></code> thì <em>entropy</em> thu được bằng bao nhiêu?</p></li>
<li><p>Hãy tính <em>entropy</em> cho trường hợp nếu <em>node gốc</em> là <em>cloudy</em> và <em>sunny</em>. So sánh <em>entropy</em> thu được giữa 3 nodes và kết luận đâu là biến phù hợp nhất tại vị trí <em>node gốc</em>?</p></li>
<li><p>Tiếp tục lựa chọn ra node con tiếp theo phù hợp nhất dựa trên giá trị <em>hàm tin thu</em> thu được là lớn nhất.</p></li>
</ol>
</div>
<div class="section" id="truong-hop-khong-phai-cay-nhi-phan">
<h2>8.5.2. Trường hợp không phải cây nhị phân<a class="headerlink" href="#truong-hop-khong-phai-cay-nhi-phan" title="Permalink to this headline">¶</a></h2>
<p>Ở trên là bài toán tối ưu cho trường hợp cây nhị phân (mỗi node quyết định chỉ gôm hai nhánh rẽ). Chúng ta có thể khái quát bài toán cho trường hợp sau rẽ nhánh tập <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> tạo thành <span class="math notranslate nohighlight">\(k\)</span> tập <span class="math notranslate nohighlight">\(\mathcal{S}_1, \mathcal{S}_2,\dots,\mathcal{S}_{k}\)</span>. Khi đó hàm <em>entropy</em> sau phân chia:</p>
<div class="math notranslate nohighlight">
\[\mathbf{H}(x^{(j)}, \mathbf{t}; \mathcal{S}) = \sum_{i=1}^{k}\frac{N_i}{N}\mathbf{H}(\mathcal{S}_i)\]</div>
<p>Với <span class="math notranslate nohighlight">\(\mathbf{t} = (t_1, t_2, \dots, t_k-1)\)</span> là véc tơ các ngưỡng phân chia để tạo thành <span class="math notranslate nohighlight">\(k\)</span> tập con.</p>
<p>và <em>hàm tin thu</em>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}\mathbf{G}(x^{(j)}, \mathbf{t}; \mathcal{S}) &amp; = &amp; \mathbf{H}(\mathcal{S}) - \mathbf{H}(x^{(j)}, \mathbf{t}; \mathcal{S}) \\
&amp; = &amp; \mathbf{H}(\mathcal{S}) - \sum_{i=1}^{k}\frac{N_i}{N}\mathbf{H}(\mathcal{S}_i)\end{eqnarray}\end{split}\]</div>
<p>Giải thuật tìm kiếm tham lam cũng thực hiện từ trên xuống dưới và truy hồi tương tự như với trường hợp nhị phân.</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="chi-so-gini">
<h1>8.6. Chỉ số Gini<a class="headerlink" href="#chi-so-gini" title="Permalink to this headline">¶</a></h1>
<p>Chỉ số Gini là một lựa chọn khác bên cạnh hàm <em>entropy</em> được sử dụng để đo lường mức độ bất bình đẳng trong phân phối của các lớp. Chỉ số này được tính bằng cách lấy 1 trừ đi tổng bình phương tỷ lệ phần trăm ở mỗi lớp.</p>
<div class="math notranslate nohighlight">
\[\text{Gini} = 1-\sum_{i=1}^{C} p_i^2\]</div>
<p>Với <span class="math notranslate nohighlight">\(\sum_{i=1}^C p_i = 1\)</span> do <span class="math notranslate nohighlight">\(p_i\)</span> là xác suất tương ứng với <span class="math notranslate nohighlight">\(p_i = p(y=i)\)</span>.</p>
<p>Một cách khá dễ dàng ta chứng minh được giá trị của <em>Gini</em> dao động trong khoảng từ 0 đến <span class="math notranslate nohighlight">\(1-\frac{1}{C}\)</span>. Thật vậy.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}(\underbrace{\sum_{i=1}^C p_i}_{1})^2 &amp; = &amp; \sum_{i=1}^C p_i^2 + 2\sum_{C \geq i &gt; j \geq 1} p_i p_j \geq \sum_{i=1}^C p_i^2 \\
\leftrightarrow 1 &amp; \geq &amp; \sum_{i=1}^C p_i^2 \tag{1}
\end{eqnarray}\end{split}\]</div>
<p>Đẳng thức xảy ra khi phân phối xác suất <span class="math notranslate nohighlight">\(\mathbf{p}\)</span> hoàn toàn thuộc về một lớp, tức ta thu được một cách phân chia tại node lá là tinh khiến thuần tuý mà không bị vẩn đục.</p>
<p>Ở khía cạnh khác, theo bất đẳng thức cauchuy-schawrz thì:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray}(\sum_{i=1}^{C}p_i)^2 &amp; \leq &amp; C (\sum_{i=1}^{C} p_i^2) \\
\leftrightarrow &amp; \frac{1}{C}\leq &amp; \sum_{i=1}^{C} p_i^2 \tag{2}
\end{eqnarray}\end{split}\]</div>
<p>Đẳng thức thu được khi phân phối xác suất hoàn toàn là đồng đều giữa các lớp. Đây là trường hợp được xem là vẩn đục mà chúng ta không mong đợi xảy ra vì mục tiêu của phân chia vẫn là các quan sát bị dồn về một nhóm.</p>
<p>Như vậy từ <span class="math notranslate nohighlight">\((1)\)</span> và <span class="math notranslate nohighlight">\((2)\)</span> ta suy ra <span class="math notranslate nohighlight">\(0 \leq \text{Gini} \leq 1-\frac{1}{C}\)</span>.</p>
<p>Gini thường được dùng đối với những biến rời rạc có số lượng các trường hợp là lớn vì nó có tốc độ tính toán nhanh hơn so với hàm entropy. Trong thuật toán CART của sklearn thì chỉ số gini được sử dụng thay cho hàm entropy.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="cay-quyet-dinh-cho-bai-toan-du-bao">
<h1>8.7. Cây quyết định cho bài toán dự báo<a class="headerlink" href="#cay-quyet-dinh-cho-bai-toan-du-bao" title="Permalink to this headline">¶</a></h1>
<p>Chúng ta có thể áp dụng cây quyết định cho bài toán dự báo cũng tương tự như bài toán phân loại. Điểm khác biệt đó là chúng ta không sử dụng <em>hàm tin thu</em> mà thay vào đó là độ suy giảm của phương sai (<em>reduction in variance</em>).</p>
<p>Đầu tiên chúng ta tính phương sai trước khi phân chia của biến mục tiêu <span class="math notranslate nohighlight">\(y\)</span> tại node <span class="math notranslate nohighlight">\(S\)</span>.</p>
<div class="math notranslate nohighlight">
\[\text{S}(y; \mathcal{S}) = \frac{\sum_{i=1}^{N}(y_i-\bar{y})^2}{N}\]</div>
<p>Phương sai của biến mục tiêu sau khi phân chia sẽ bằng tổng có trọng số của phương sai trên từng nhóm:</p>
<div class="math notranslate nohighlight">
\[\text{S}(y, x^{(j)}, \mathbf{t}; \mathcal{S}) = \sum_{i=1}^{k} \frac{N_i}{N}\text{S}(y;\mathcal{S_i})\]</div>
<p>Giá trị của <em>độ suy giảm phương sai</em> sau phân chia:</p>
<div class="math notranslate nohighlight">
\[\text{RV}(y, x^{(j)}, \mathbf{t}; \mathcal{S}) = \text{S}(y; \mathcal{S}) - \text{S}(y, x^{(j)}, \mathbf{t}; \mathcal{S})\]</div>
<p>Thuật toán tìm kiếm tham lam sẽ tìm cách lựa chọn <span class="math notranslate nohighlight">\(x_i\)</span> và ngưỡng phân chia sao cho <em>độ suy giảm phương sai</em> <span class="math notranslate nohighlight">\(\text{RV}(y, x_j, \mathbf{t}; \mathcal{S})\)</span> là lớn nhất. Điều này cũng có nghĩa rằng các quan sát được phân về cùng một node lá thì có giá trị dự báo sát nhau. Như vậy ta có thể đưa ra một ước lượng chung cho node lá bằng trung bình cộng của biến mục tiêu mà không lo lắng giá trị dự báo bị chệch. Như vậy giá trị ước lượng của một quan sát <span class="math notranslate nohighlight">\((\mathbf{x}_i, y_i)\)</span> thuộc về node <span class="math notranslate nohighlight">\(\mathcal{S}_j\)</span> sẽ bằng trung bình cộng biến mục tiêu của node:</p>
<div class="math notranslate nohighlight">
\[\hat{y}_i = \frac{1}{|S_j|}\sum_{k=1}^{|S_j|} y_k\]</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="dieu-kien-dung-de-giam-qua-khop-overfitting">
<h1>8.8. Điều kiện dừng để giảm quá khớp (<em>overfitting</em>)<a class="headerlink" href="#dieu-kien-dung-de-giam-qua-khop-overfitting" title="Permalink to this headline">¶</a></h1>
<p>Nếu chúng ta tiếp tục phân chia cây quyết định liên tục thì số lượng các quan sát ở mỗi node lá sẽ giảm dần. Cho tới một ngưỡng độ sâu <span class="math notranslate nohighlight">\(p\)</span> nào đó, số quan sát còn lại ở mỗi node lá sẽ rất nhỏ và thậm chí chỉ một vài quan sát. Các kết quả dự báo dựa trên tập mẫu rất nhỏ này không còn mang tính tổng quát và do đó hiện tượng <em>quá khớp</em> thường xảy ra. Để tránh hiện tượng quá khớp cũng như tiết kiệm chi phí tính toán, chúng ta sẽ dừng việc phân chia khi đạt một số điều kiện:</p>
<ul class="simple">
<li><p>Độ sâu của cây nhị phân chạm một ngưỡng tối thiểu.</p></li>
<li><p>Số lượng các quan sát của một node lá đạt ngưỡng tối thiểu. Chẳng hạn như: 30 quan sát thuộc node lá cho bài toán phân loại nhị phân thì quyết định phân lớp là đủ tin cậy.</p></li>
<li><p>Node lá hoàn toàn thuộc về một nhóm duy nhất. Tức node phân chia là hoàn toàn tinh khiết.</p></li>
<li><p>Số lượng các node phân chia đạt ngưỡng.</p></li>
<li><p>Số lượng các node lá đạt ngưỡng. Số lượng node lá càng nhiều thì mô hình càng trở nên phức tạp.</p></li>
<li><p><em>hàm tin thu</em> giảm dưới một ngưỡng rất nhỏ. Đồng nghĩa với việc phân chia thêm cũng không có nhiều ý nghĩa.</p></li>
</ul>
<p>Ngoài các phương pháp giảm thiểu quá khớp nêu trên chúng ta còn có thể giảm thiểu quá khớp thông qua phương pháp <em>cắt tỉa</em> (<em>pruning</em>).</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="cat-tia-pruning">
<h1>8.9. Cắt tỉa  (<em>pruning</em>)<a class="headerlink" href="#cat-tia-pruning" title="Permalink to this headline">¶</a></h1>
<p>Nội dung của phương pháp cắt tỉa đó là đầu tiên chúng ta sẽ huấn luyện mô hình cây quyết định trên tập tập huấn luyện (<em>train dataset</em>) sao cho toàn bộ các quan sát đều được phân loại về đúng nhãn. Sau đó loại bỏ dần các node lá ở bên dưới và chuyển node cha trực tiếp của chúng thành node lá. Các node lá chỉ bị loại bỏ khi độ chính xác dự báo trên tập kiểm định (validation dataset) được cải thiện. Quá trình sẽ dừng khi độ chính xác trên tập kiểm tra không còn tiếp tục được cải thiện. Phương pháp trên được gọi là phương pháp <em>giảm thiểu sai số cắt tỉa</em> (<em>reducing error pruning</em>).</p>
<p>Ngoài ra còn một kỹ thuật khác sẽ tìm cách giảm thiểu mức độ cồng kềnh của cây quyết định thông qua kiểm soát số lượng <em>node lá</em>. Theo đó phương pháp này cộng thêm thành phần <span class="math notranslate nohighlight">\(K\)</span> là số lượng <em>node lá</em> vào hàm mất mát là tổng entropy có trọng số của các node con. Giả sử cây quyết định cuối cùng phân loại đúng toàn bộ các quan sát về <span class="math notranslate nohighlight">\(K\)</span> tập tại node lá là <span class="math notranslate nohighlight">\(\mathcal{S}_1, \mathcal{S}_2, \dots , \mathcal{S}_K\)</span>:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\text{final_tree}) = \sum_{i=1}^{K} \frac{|\mathcal{S}_i|}{N} \mathbf{H}(\mathcal{S}_i) + \lambda K\]</div>
<p>Trong đó <span class="math notranslate nohighlight">\(N\)</span> là số lượng quan sát và <span class="math notranslate nohighlight">\(|\mathcal{S}_i|\)</span> là kích thước của node lá.</p>
<p>Cũng giống như các phương pháp điều chuẩn khác, chúng ta lựa chọn <span class="math notranslate nohighlight">\(\lambda\)</span> là một giá trị dương tương đối nhỏ đại diện cho thành phần kiểm soát. Gía trị này lớn thể hiện vai trò của số lượng node lá tác động lên hàm chi phí lớn. Ở thời điểm ban đầu để phân loại đúng toàn bộ các quan sát thì cần số lượng node lá là <span class="math notranslate nohighlight">\(K\)</span> tương đối lớn. Sau đó chúng ta sẽ cắt tỉa dần cây quyết định sao cho mỗi một lượt cắt tỉa hàm mất mát giảm một lượng là lớn nhất. Quá trình cắt tỉa sẽ dừng cho tới khi hàm mất mát không còn tiếp tục giảm được nữa.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="tuning-sieu-tham-so-cho-mo-hinh-cay-quyet-dinh">
<h1>8.10. Tuning siêu tham số cho mô hình cây quyết định<a class="headerlink" href="#tuning-sieu-tham-so-cho-mo-hinh-cay-quyet-dinh" title="Permalink to this headline">¶</a></h1>
<p>Trong thuật toán cây quyết định chúng ta có thể quan tâm tới một số tham số có thể được sử dụng để tuning. Đó là những tham số chính bên dưới:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> 
<span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> 
<span class="n">splitter</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> 
<span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
<span class="n">min_samples_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
<span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
<span class="n">max_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="n">max_leaf_nodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
<span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> 
<span class="n">min_impurity_split</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Trong đó:</p>
<ul class="simple">
<li><p>criterion: Là hàm số để đo lường chất lượng phân chia ở mỗi node. Có hai lựa chọn là <code class="docutils literal notranslate"><span class="pre">gini</span></code> và <code class="docutils literal notranslate"><span class="pre">entropy</span></code>.</p></li>
<li><p>max_depth: Độ sâu tối đa cho một cây quyết định. Đối với mô hình bị quá khớp thì chúng ta cần giảm độ sâu và vị khớp thì gia tăng độ sâu.</p></li>
<li><p>min_samples_split: Kích thước mẫu tối thiểu được yêu cầu để tiếp tục phân chia đối với node quyết định. Được sử dụng để tránh kích thước của node lá quá nhỏ nhằm giảm thiểu hiện tượng quá khớp.</p></li>
<li><p>max_features: Số lượng các biến được lựa chọn để tìm kiếm ra biến phân chia tốt nhất ở mỗi lượt phân chia.</p></li>
<li><p>max_leaf_nodes: Số lượng các node lá tối đa của cây quyết định. Thường được thiết lập khi muốn kiểm soát hiện tượng quá khớp.</p></li>
<li><p>min_impurity_decrease: Chúng ta sẽ tiếp tục phân chia một node nếu như sự suy giảm của độ tinh khiết nếu phân chia lớn hơn ngưỡng này.
im</p></li>
<li><p>min_impurity_split: Ngưỡng dừng sớm để kiểm soát sự gia tăng của cây quyết định. Thường được sử dụng để tránh hiện tượng quá khớp. Chúng ta sẽ tiếp tục chia node nếu độ tinh khiết cao hơn ngưỡng này.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;clf__max_depth&#39;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="s1">&#39;clf__criterion&#39;</span><span class="p">:[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">],</span>
    <span class="s1">&#39;clf__min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> 
    <span class="s1">&#39;clf__min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">13</span><span class="p">],</span>
    <span class="s1">&#39;clf__max_leaf_nodes&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>   
<span class="p">}</span>


<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;clf&quot;</span><span class="p">,</span> <span class="n">DecisionTreeClassifier</span><span class="p">())]</span>
<span class="p">)</span>

<span class="n">gscv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">error_score</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">gscv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="bai-tap">
<h1>8.11. Bài tập<a class="headerlink" href="#bai-tap" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p>Một cây nhị phân có độ sâu là 5. Hỏi số lượng các node lá của nó là bao nhiêu?</p></li>
<li><p>Nếu cây nhị phân trên có được hồi qui trên một bộ dữ liệu kích thước là 10000 quan sát thì trung bình mỗi node lá có bao nhiêu quan sát ? Số lượng quan sát này có đủ lớn để tin cậy vào kết luận phân loại ở các node lá không ?</p></li>
<li><p>Một cây quyết định có độ sâu là 5 thì giá trị dự báo về nhãn của nó được tạo thành từ bao nhiêu câu hỏi ?</p></li>
<li><p>Một bài toán phân loại gồm 5 lớp. Giá trị hàm entropy lớn nhất có thể thu được ở mỗi node lá là bao nhiêu?</p></li>
<li><p>Gía trị lớn nhất của chỉ số Gini thu được ở bài toán phân loại ở câu 3 nhưng áp dụng trên mỗi node lá là bao nhiêu?</p></li>
<li><p>Khi mô hình gặp hiện tượng quá khớp thì chúng ta nên tăng độ sâu hay giảm độ sâu của cây quyết định?</p></li>
<li><p>Trong bài toán dự báo thì giá trị dự báo của các quan sát thuộc cùng một node được tính như thế nào?</p></li>
<li><p>Sử dụng bộ dữ liệu iris. Hãy xây dựng bài toán dự báo biến mục tiêu là 1: nếu rơi vào loài hoa Versicolor và 0 nếu là các loài hoa còn lại. Biến đầu vào là 4 trường kích thước dài, rộng của đài hoa và cánh hoa. Hãy thực hiện grid search trên các tham số chẳng hạn như độ sâu, số lượng mẫu tối thiểu tại node lá, số lượng node lá tối đa,… để tìm ra mô hình có độ chính xác tốt nhất.</p></li>
</ol>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="tai-lieu-tham-khao">
<h1>8. 12. Tài liệu tham khảo<a class="headerlink" href="#tai-lieu-tham-khao" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p><a class="reference external" href="https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052">https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052</a></p></li>
<li><p><a class="reference external" href="https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html">https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html</a></p></li>
<li><p><a class="reference external" href="https://towardsdatascience.com/under-the-hood-decision-tree-454f8581684e">https://towardsdatascience.com/under-the-hood-decision-tree-454f8581684e</a></p></li>
<li><p><a class="reference external" href="https://machinelearningcoban.com/2018/01/14/id3/">https://machinelearningcoban.com/2018/01/14/id3/</a></p></li>
</ol>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ch_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="index_DecisionTree.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">8. Khái niệm về cây quyết định</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="index_RandomForest.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">9. Giới thiệu về mô hình rừng cây (<em>Random Forest</em>)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Pham Dinh Khanh<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>