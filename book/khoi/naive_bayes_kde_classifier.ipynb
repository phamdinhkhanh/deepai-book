{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd04621005da5c26ac209901ca167bf25025457b064ec855aea9ba97365ac8d4984",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Phân Loại Xác Suất (Probabilistic Classifier): Naive Bayes và KDE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "source": [
    "Chúng ta bắt đầu bằng 1 bài toán xác suất cơ bản: \n",
    "\n",
    "> Một ngày đẹp trời, bạn đi xem thầy bói. Thầy phán rằng bạn sẽ ế trước khi bạn 30. Bạn biết rằng trước đó có 10 người bạn già của bạn cũng đi xem ông này bói, và có 6 người ông ấy phán là sẽ ế. Trong 6 người đó, có 2 người sau này lại có người yêu trước 30, còn 4 người ông ấy phán không ế, có 1 ông tới năm 30 vẫn phải quẹt Tinder. Bạn thắc mắc rằng, khả năng mình ế thật sự sẽ là bao nhiêu phần trăm?\n",
    "\n",
    "Trong các phương pháp để phân loại dữ liệu, sử dụng xác suất là một trong những phương pháp phổ biến nhất. Từ 1 tập dữ liệu có sẵn, ta có thể tính toán ra các xác suất của từng phân loại cho mỗi thực thể T. Và hiển nhiên, các mô hình này sẽ chọn phân loại khả thi nhất cho thực thể đó:\n",
    "\n",
    "$$$\n",
    "class(T) = argmax_{c_i}[P(c_i|T)]\n",
    "$$$\n",
    "\n",
    "> 'Tên gì? Nhà quận mấy? Có xe chưa?...'\n",
    "\n",
    "Tất nhiên khi xem bói, thì ông thầy bói cũng hỏi bạn đủ thứ số mệnh rồi. Trong những trường hợp 1 thực thể T có nhiều đặc điểm x, thì mô hình sẽ tổng hợp xác suất cho mỗi đặc điểm, rồi cộng lại với nhau:\n",
    "\n",
    "$$$\n",
    "class(T) = argmax_{c_i}\\Big[\\sum_{x_j \\in T} P(c_i|x_j)\\Big]\n",
    "$$$\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "THẦY BÓI TÌNH DUYÊN 4.0\n",
      "********************************************************************************\n",
      "   đẹp trai  thích ăn rau muống  học giỏi      Ế\n",
      "0     False                True     False   True\n",
      "1     False               False     False   True\n",
      "2     False                True     False   True\n",
      "3      True                True      True   True\n",
      "4      True               False     False  False\n",
      "5      True                True      True  False\n",
      "6     False                True     False   True\n",
      "7      True               False      True  False\n",
      "8      True                True      True  False\n",
      "9     False               False     False  False\n",
      "********************************************************************************\n",
      "P(Ế | đẹp trai = True): 0.20\t\t\t P(Ế | đẹp trai = False): 0.80\n",
      "P(Không Ế | đẹp trai = True): 0.80\t\t P(Không Ế | đẹp trai = False): 0.20\n",
      "P(Ế | thích ăn rau muống = True): 0.80\t\t\t P(Ế | thích ăn rau muống = False): 0.20\n",
      "P(Không Ế | thích ăn rau muống = True): 0.40\t\t P(Không Ế | thích ăn rau muống = False): 0.60\n",
      "P(Ế | học giỏi = True): 0.20\t\t\t P(Ế | học giỏi = False): 0.80\n",
      "P(Không Ế | học giỏi = True): 0.60\t\t P(Không Ế | học giỏi = False): 0.40\n",
      "\n",
      " P(Ế) = P(Ế | đẹp trai = True) + P(Ế | thích ăn rau muống = True) + P(Ế | học giỏi = True) = 1.20\n",
      " P(Không Ế) = P(Không Ế | đẹp trai = False) + P(Không Ế | thích ăn rau muống = False) + P(Không Ế | học giỏi = False) = 1.80\n",
      "\n",
      "Bạn còn cơ hội trước 30. Quẩy lên.\n"
     ]
    }
   ],
   "source": [
    "test = defaultdict(str)\n",
    "p_e_given_true = defaultdict(float)\n",
    "p_e_given_false = defaultdict(float)\n",
    "p_not_e_given_true = defaultdict(float)\n",
    "p_not_e_given_false = defaultdict(float)\n",
    "trait_list = []\n",
    "non_trait_list = []\n",
    "\n",
    "print(\"THẦY BÓI TÌNH DUYÊN 4.0\")\n",
    "# Nhập và phân tách dữ liệu\n",
    "data = pd.read_csv('train.csv').select_dtypes(include = 'bool')\n",
    "print(\"*\"*80)\n",
    "print(data)\n",
    "print(\"*\"*80)\n",
    "true_data = data.loc[data['Ế']==True]\n",
    "false_data = data.loc[data['Ế']==False]\n",
    "\n",
    "# Tổng hợp lại từng xác suất trong từng trường hợp, đồng thời hỏi thông tin người xem bói\n",
    "for c in data.columns[:-1]:\n",
    "    test[c] = input(\"Bạn có \" + c + \" không? (Y/N)\") in 'YESYesyes'\n",
    "    true_col = true_data.loc[true_data[c]==True]\n",
    "    false_col = false_data.loc[false_data[c]==True]\n",
    "    p_e_given_true[c] = len(true_col)/len(true_data)\n",
    "    p_e_given_false[c] = 1-p_e_given_true[c]\n",
    "    p_not_e_given_true[c] = len(false_col)/len(false_data)\n",
    "    p_not_e_given_false[c] = 1-p_not_e_given_true[c]\n",
    "\n",
    "    print(f\"P(Ế | {c:s} = True): {p_e_given_true[c]:.2f}\\t\\t\\t P(Ế | {c:s} = False): {p_e_given_false[c]:.2f}\")\n",
    "    print(f\"P(Không Ế | {c:s} = True): {p_not_e_given_true[c]:.2f}\\t\\t P(Không Ế | {c:s} = False): {p_not_e_given_false[c]:.2f}\")\n",
    "\n",
    "# Tổng các xác suất cho \"ế\" và \"không ế\"\n",
    "e_total = sum([p_e_given_true[c] if test[c] else p_e_given_false[c] for c in data.columns[:-1]])\n",
    "khong_e_total = len(data.columns[:-1])-e_total\n",
    "\n",
    "print(\"\\n P(Ế) = \" + \" + \".join([f\"P(Ế | {c:s} = {str(test[c]):s})\" for c in data.columns[:-1]]) + f\" = {e_total:.2f}\")\n",
    "print(\" P(Không Ế) = \" + \" + \".join([f\"P(Không Ế | {c:s} = {str(not test[c]):s})\" for c in data.columns[:-1]]) + f\" = {khong_e_total:.2f}\\n\")\n",
    "\n",
    "res = \"ế chỏng chơ tới 30, đen thôi đỏ quên đi.\" if e_total > khong_e_total else \"còn cơ hội trước 30. Quẩy lên.\"\n",
    "print(f\"Bạn {res:s}\")\n"
   ]
  },
  {
   "source": [
    "Để có thể đủ dữ liệu để so sánh, với $c$ phân loại, $m$ đặc điểm, mỗi đặc điểm gồm $k$ loại, ta cần $O(ck^m)$ để có thể dự đoán cho mọi trường hợp. Nhưng thực tế, không làm mà đòi có ăn là không được, dữ liệu không phải lúc nào cũng có đầy đủ. Nếu như mỗi cá thể có tới trên 20 biến nhị phân, thì sẽ cần tối thiểu $c \\times 2^{20} \\approx c \\times 10^6$ dữ liệu. Và vì vậy, cần có một phương pháp phù hợp hơn để phân loại, thay vì cứ gom lại."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Naive Bayes - Biến rời rạc\n",
    "### 1.1 Mô hình\n",
    "Cách đơn giản nhất để xử lí việc không có đủ dữ liệu trùng khớp để so sánh, đó là tìm ngược lại rằng liệu mỗi phân loại có thể có những đặc điểm trên hay không. Thay vì tìm một người như bạn rồi xem người đó có ế hay không, ông thầy sẽ tìm xem người ế thường giống bạn chỗ nào không. Nói một cách toán học, thì ta sẽ tìm $P(x_j|c_i)$ từ $P(c_i|x_j)$. Nguyên lí Bayes là công thức ta cần để đạt được việc này:\n",
    "\n",
    "$$$\n",
    "P(H|x)=\\frac{P(x|H)P(H)}{P(x)}\n",
    "$$$\n",
    "\n",
    "Những gì ta cần là:\n",
    "* $P(H|x)$ - Những đối tượng có đặc tính $x$ có bao nhiêu phần thuộc phân loại $H$?\n",
    "* $P(H)$ - Phân loại $H$ chiếm bao nhiêu phần trong tập thể?\n",
    "* $P(x)$ - Đặc điểm $x$ chiếm bao nhiêu phần trong tập thể?\n",
    "\n",
    "Bằng công thức này, ta sẽ chọn phân loại có nhiều đặc tính trùng khớp với đối tượng nhất:\n",
    "\n",
    "$$$\n",
    "class(T) = argmax_{c_i}\\Big[\\frac{P(T|c_i)P(c_i)}{P(T)}\\Big]\n",
    "$$$\n",
    "\n",
    "Với nhiều đặc điểm, nguyên lí Bayes sẽ giả định rằng những đặc điểm này độc lập lẫn nhau cho dễ tính, và điều này tạo nên cái tên \"Naive\" (nai tơ). Như vậy, ta có thể sử dụng công thức tính xác suất của các đặc điểm độc lập:\n",
    "\n",
    "$$$\n",
    "P(x_1,x_2,...,x_n|c) = \\prod_{x_i \\in T} P(x_i|c)\n",
    "$$$\n",
    "\n",
    "Bằng cách thay thực thể $T$ bằng 1 dãy đặc điểm $[x_1,x_2,...,x_n]$, công thức sẽ trở thành:\n",
    "\n",
    "$$$\n",
    "class(T) = argmax_{c_i}\\Big[\\frac{P(c_i)\\prod_{x_i \\in T} P(x_i|c)}{P(T)}\\Big]\n",
    "$$$\n",
    "\n",
    "Khoan, dừng lại khoảng chừng là 20 giây! Có thể rút gọn phần nào phương trình này không?\n",
    "\n",
    "Chúng ta có thể để ý rằng dù cho phân loại có là gì, thì xác suất tìm được các đặc tính trong một tập thể $P(T)$ vẫn giữ nguyên và không làm ảnh hưởng đến trật tự của các kết quả. Và vì vậy, con số này không nhất thiết phải mang vào công thức, vì mục đích cuối cùng của mô hình vẫn là so sánh để tìm ra xác suất lớn nhất mà thôi:\n",
    "\n",
    "$$$\n",
    "class(T) = argmax_{c_i}\\Big[P(c_i)\\prod_{x_i \\in T} P(x_i|c)\\Big]\n",
    "$$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "THẦY BÓI TÌNH DUYÊN 4.0.1\n",
      "********************************************************************************\n",
      "   đẹp trai  thích ăn rau muống  học giỏi      Ế\n",
      "0     False                True     False   True\n",
      "1     False               False     False   True\n",
      "2     False                True     False   True\n",
      "3      True                True      True   True\n",
      "4      True               False     False  False\n",
      "5      True                True      True  False\n",
      "6     False                True     False   True\n",
      "7      True               False      True  False\n",
      "8      True                True      True  False\n",
      "9     False               False     False  False\n",
      "********************************************************************************\n",
      "Bạn còn cơ hội trước 30. Quẩy lên.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "input_info = []\n",
    "\n",
    "print(\"THẦY BÓI TÌNH DUYÊN 4.0.1\")\n",
    "data = pd.read_csv('train.csv').select_dtypes(include = 'bool')\n",
    "print(\"*\"*80)\n",
    "print(data)\n",
    "print(\"*\"*80)\n",
    "for c in data.columns[:-1]:\n",
    "    input_info.append(input(\"Bạn có \" + c + \" không? (Y/N)\") in 'YESYesyes')\n",
    "\n",
    "x = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "clf = CategoricalNB(alpha = 0.5) # Laplace Smoothing, xem 1.2.3\n",
    "clf.fit(x, y)\n",
    "\n",
    "out = clf.predict([input_info])\n",
    "res = \"ế chỏng chơ tới 30, đen thôi đỏ quên đi.\" if out[0] else \"còn cơ hội trước 30. Quẩy lên.\"\n",
    "print(f\"Bạn {res:s}\")"
   ]
  },
  {
   "source": [
    "Bằng cách tổng hợp các xác suất từ dữ liệu có sẵn, ta có thể thấy mô hình Naive Bayes là một mô hình supervised đưa ra dự đoán từ thông tin có sẵn, giả định sự độc lập của các đặc điểm để tính toán thuận tiện hơn. Tuy nhiên ngoài thực tế, hầu hết các đặc điểm đều không độc lập hoàn toàn khỏi các đặc điểm khác, và vì thế mô hình này không hoàn toàn chính xác. Dù vậy, Naive Bayes vẫn trở nên hiệu quả trong hầu hết các trường hợp, và là một trong các mô hình phân loại phổ biến trong Machine Learning. Thực tế thì ông thầy bói mà nói toẹt ra rằng việc bạn thế này không ảnh hưởng tới việc bạn thế kia thì còn ai mà đi xem bói nữa đâu hehe.\n",
    "\n",
    "### 1.2 Tie breaking\n",
    "\n",
    "> Nếu bạn muốn bói tình duyên cho con Vitamin Gâu Gâu nhà bạn, liệu ông thầy bói có dự đoán được không?\n",
    "\n",
    "Khi dự đoán, nếu một đặc điểm không thể xảy ra trong 1 phân loại, thì hiển nhiên xác suất cá thể đó thuộc phân loại kể trên là 0. Chính tại đây, khuyết điểm của mô hình Naive Bayes xuất hiện khi 1 cá thể có những đặc tính hiếm gần như chưa được thấy bao giờ, và vì vậy trở nên bất khả thi cho hầu hết mọi trường hợp. Và vì vậy, cần một phương pháp hợp lí để phân định rõ ràng những cá thể trên.\n",
    "\n",
    "#### 1.2.1 Phân loại ngẫu nhiên\n",
    "Đúng như tên gọi, phương pháp này là \"vạn sự tùy duyên\".\n",
    "\n",
    "#### 1.2.2 Thay biến epsilon\n",
    "Thay vì nói rằng xác suất bằng 0 là *bất khả thi* cho 1 phân loại $c$, có thể thay đổi cách nói thành *ca này khó*. Thay vì đưa 0 vào tích các xác suất, ta có thể đưa vào 1 con số $\\epsilon < \\frac{1}{count(c_i)}$. Như vậy, ta sẽ có 1 loạt ca khó, nhưng khi mà ca nào cũng khó, cái ít khó nhất hiển nhiên trở thành điều khả thi nhất.\n",
    "\n",
    "#### 1.2.3 Laplace Smoothing - Tịnh tiến Laplace\n",
    "Một cách khác để thay *bất khả thi* thành *ca này khó* là đếm dư thêm 1 (hoặc 1 số $\\alpha \\in [0,1]$) trường hợp cho mỗi đặc điểm $x_i$:\n",
    "\n",
    "$$$\n",
    "P_i = \\frac{x_i}{N} \\text{(Nguyên bản)} = \\frac{x_i + \\alpha}{N + \\alpha d} \\text{(Đã tịnh tiến, d = Số thực thể)}\n",
    "$$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Naive Bayes - Biến liên tục\n",
    "\n",
    "> 'Tuổi? Cao bao nhiêu? BMI?...'\n",
    "\n",
    "Sẽ dễ dàng biết mấy nếu ông thầy bói chỉ hỏi những câu hỏi mà bạn chỉ việc trả lời có hoặc không. Nhưng nếu như bạn phải trả lời bằng một con số (ví dụ như tuổi, chiều cao, ...) thì sao? Phương pháp Naive Bayes kể trên sử dụng tốt cho những biến rời rạc, nhưng khi những đặc điểm không chỉ là phân loại, mà là các con số đo đạc, cần phải có những cải biến cho mô hình để có thể áp dụng biến liên tục vào dự đoán."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.1 Phân tách\n",
    "\n",
    "Có thể phân dữ liệu của 1 biến liên tục thành các phần khác nhau, và phân loại cho từng phần thành 1 nhóm chung. \n",
    "\n",
    "#### 2.1.1 Phân tách theo khoảng (Uniform Discretization)\n",
    "> 'Ngày sinh $\\rightarrow$ Cung hoàng đạo'\n",
    "\n",
    "Tìm khoảng giá trị của các dữ liệu, và chia đều thành $n$ khoảng nhỏ. Dữ liệu nằm trong cùng 1 khoảng giá trị đã chia sẽ được gộp thành 1 nhóm. \n",
    "\n",
    "#### 2.2.2 Phân tách theo số lượng (Quantile Discretization)\n",
    "> 'MMR $\\rightarrow$ Rank LoL (Top %)'\n",
    "\n",
    "Sắp xếp thứ tự lại cho dữ liệu từ thấp đến cao hoặc ngược lại. Lấy $n$ dữ liệu đầu tiên gộp thành một nhóm, và cứ thế lặp lại cho mỗi $n$ (hoặc 1 số lượng khác tùy ý) dữ liệu tiếp theo.\n",
    "\n",
    "#### 2.2.3 Các phương pháp clustering khác\n",
    "> 'Địa chỉ $\\rightarrow$ Nhà nghỉ gần nhất'\n",
    "\n",
    "*Xem thêm: K-Means Clustering và KNN (Chương 4)*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   lương tháng  Uniform  Quantile  K-Means\n",
       "0   30000000.0      1.0       4.0      0.0\n",
       "1    7000000.0      0.0       2.0      0.0\n",
       "2   15000000.0      0.0       3.0      0.0\n",
       "3    3000000.0      0.0       0.0      0.0\n",
       "4    5000000.0      0.0       1.0      0.0\n",
       "5   12000000.0      0.0       2.0      0.0\n",
       "6    5500000.0      0.0       1.0      0.0\n",
       "7   25000000.0      1.0       3.0      0.0\n",
       "8    4000000.0      0.0       0.0      0.0\n",
       "9  100000000.0      4.0       4.0      1.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lương tháng</th>\n      <th>Uniform</th>\n      <th>Quantile</th>\n      <th>K-Means</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30000000.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7000000.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15000000.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3000000.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5000000.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>12000000.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5500000.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>25000000.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4000000.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>100000000.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "data = pd.read_csv('train.csv').iloc[:,-2:]\n",
    "X = data.iloc[:,:-1]\n",
    "\n",
    "unif = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "kmeans = KBinsDiscretizer(n_bins=2, encode='ordinal', strategy='kmeans')\n",
    "quant = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "\n",
    "u = unif.fit_transform(X)\n",
    "data[\"Uniform\"]=u\n",
    "\n",
    "q = quant.fit_transform(X)\n",
    "data[\"Quantile\"]=q\n",
    "\n",
    "k = kmeans.fit_transform(X)\n",
    "data[\"K-Means\"]=k\n",
    "\n",
    "data.drop(data.columns[1],axis=1)"
   ]
  },
  {
   "source": [
    "Việc phân tách có thể hiệu quả trong việc giản lược số liệu, nhưng đồng thời cũng sẽ làm giảm đi lượng thông tin có được. Một trong các cách để có thể giữ được lại nhiều thông tin nhất, đó là sử dụng phân phối để tính ra xác suất."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.2 Gaussian Naive Bayes\n",
    "Gaussian Naive Bayes vận hành như mô hình Naive Bayes thuần túy, nhưng lấy xác suất từ công thức phân phối Gaussian (phân phối chuẩn):\n",
    "\n",
    "$$$\n",
    "P(x_i|c) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-0.5\\displaystyle \\big(\\frac{x_i-\\mu}{\\sigma}\\big)^2} \\\\\n",
    "\n",
    "x_i \\in N(\\mu,\\sigma),\n",
    "\\;\\;\\;\\;\\;\n",
    "\\mu = \\sum_{x_i} \\frac{x_i}{N},\n",
    "\\;\\;\\;\\;\\;\n",
    "\\sigma = \\sqrt{\\frac{\\sum^N_{i=1} (x_i-\\mu)^2}{N-1}}\n",
    "$$$\n",
    "\n",
    "Và ta có thể thấy hiển nhiên rằng mô hình này giả định rằng dữ liệu được phân bố chuẩn. Điều này đúng trong hầu hết các trường hợp, khi mà phân phối chuẩn có thể dùng để ước lượng thay cho phần lớn các phân phối khác như nhị thức, Possion, Chi-square,..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "THẦY BÓI TÌNH DUYÊN 4.0.1\n",
      "****************************************\n",
      "   lương tháng      Ế\n",
      "0   30000000.0   True\n",
      "1    7000000.0   True\n",
      "2   15000000.0   True\n",
      "3    3000000.0   True\n",
      "4    5000000.0  False\n",
      "5   12000000.0  False\n",
      "6    5500000.0   True\n",
      "7   25000000.0  False\n",
      "8    4000000.0  False\n",
      "9  100000000.0  False\n",
      "****************************************\n",
      "Bạn ế chỏng chơ tới 30, đen thôi đỏ quên đi.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "print(\"THẦY BÓI TÌNH DUYÊN 4.0.1\")\n",
    "salary = int(input(\"Nhập lương tháng của bạn (VNĐ): \"))\n",
    "\n",
    "data = pd.read_csv('train.csv').iloc[:,-2:]\n",
    "print(\"*\"*40)\n",
    "print(data)\n",
    "print(\"*\"*40)\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X,y)\n",
    "out = clf.predict([[salary]])\n",
    "res = \"ế chỏng chơ tới 30, đen thôi đỏ quên đi.\" if out[0] else \"còn cơ hội trước 30. Quẩy lên.\"\n",
    "print(f\"Bạn {res:s}\")"
   ]
  },
  {
   "source": [
    "### 2.3 Kernel Density Estimation\n",
    "\n",
    "Tuy Gaussian Naive Bayes có thể sử dụng rộng rãi, dữ liệu ngoài thực tế thường có sự chênh lệch, và vì vậy không đảm bảo tính chính xác cao.\n",
    "\n",
    "Một cách khắc phục vấn đề này, đó là ước lượng một phân phối cụ thể và chính xác hơn cho các đặc điểm. Kernel Density Estimation (KDE) là một phương pháp tính phân phối hiệu quả trong trường hợp này:\n",
    "\n",
    "$$$\n",
    "P(x_i|c) = \\frac{1}{N}\\sum^N_{i=1}\\phi_\\sigma(x-x_i)\\\\~\\\\\n",
    "\n",
    "\\phi_\\sigma = N(0,\\sigma) \\;\\;\\; (\\sigma \\text{ tự chọn})\n",
    "$$$\n",
    "\n",
    "Phương pháp này tuy hiệu quả hơn Gaussian Naive Bayes, nhưng sẽ cần chọn kernal bandwidth $\\sigma$ hợp lí, cũng như chịu thêm thời gian tính toán khi phải tính phân phối chuẩn cho mỗi dữ liệu.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "THẦY BÓI TÌNH DUYÊN 4.0.1\n",
      "****************************************\n",
      "   lương tháng      Ế\n",
      "0   30000000.0   True\n",
      "1    7000000.0   True\n",
      "2   15000000.0   True\n",
      "3    3000000.0   True\n",
      "4    5000000.0  False\n",
      "5   12000000.0  False\n",
      "6    5500000.0   True\n",
      "7   25000000.0  False\n",
      "8    4000000.0  False\n",
      "9  100000000.0  False\n",
      "****************************************\n",
      "[-100000000000.50568, -400000000000.5057]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "print(\"THẦY BÓI TÌNH DUYÊN 4.0.1\")\n",
    "salary = int(input(\"Nhập lương tháng của bạn (VNĐ): \"))\n",
    "\n",
    "data = pd.read_csv('train.csv').iloc[:,-2:]\n",
    "print(\"*\"*40)\n",
    "print(data)\n",
    "print(\"*\"*40)\n",
    "true_data = data.loc[data['Ế']==True]\n",
    "false_data = data.loc[data['Ế']==False]\n",
    "Xtrue = true_data.iloc[:,:-1]\n",
    "Xfalse = false_data.iloc[:,:-1]\n",
    "\n",
    "kde = KernelDensity(bandwidth=1)\n",
    "\n",
    "kde.fit(Xtrue)\n",
    "outTrue = kde.score([[salary]])/len(true_data)\n",
    "\n",
    "kde.fit(Xfalse)\n",
    "outFalse = kde.score([[salary]])/len(false_data)\n",
    "\n",
    "print([outTrue,outFalse])\n",
    "#res = \"ế chỏng chơ tới 30, đen thôi đỏ quên đi.\" if out[0] else \"còn cơ hội trước 30. Quẩy lên.\"\n",
    "#print(f\"Bạn {res:s}\")"
   ]
  },
  {
   "source": [
    "## 3. Kết bài\n",
    "Naive Bayes, cũng như các phương pháp phân loại bằng xác suất khác trở nên thuận tiện khi ta biết được những dữ liệu trước đó, qua các bước tính toán không mang tính phức tạp cao. Trong hầu hết các trường hợp, các phương pháp xử lí phù hợp sẽ được sử dụng cho từng loại dữ liệu khác nhau. Tuy sự giả định về tính độc lập của các yếu tố sẽ làm giảm độ chính xác của mô hình, Naive Bayes vẫn giữ vai trò nhất định trong việc phân loại dữ liệu, và là một trong những thuật toán dự đoán phổ biến nhất của Machine Learning. Khi đọc xong bài hướng dẫn này, bạn đã có thể tự làm thầy bói 4.0 cho mình rồi đấy, hay thậm chí mở hàng bói cho người khác luôn. Kèo thơm thì mua tác giả cốc cà phê cám ơn là được rồi, còn kèo khắm thì tác giả xin miễn trừ trách nhiệm nhé hehehe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}